# GUI Agent 最新动态：从 Claude Computer Use 到 OpenAI Operator

> 最近 GUI Agent 领域动作不断，从 Anthropic 的 Computer Use 到 OpenAI 的 Operator，再到国内各大厂商的跟进，这个赛道正在快速升温。这篇文章整理了 2025 年以来 GUI Agent 的最新进展。

---

## Claude Computer Use：从演示到量产

Anthropic 在 2024 年底推出的 Claude 3.5 Sonnet with Computer Use 可以说是 GUI Agent 领域的里程碑。它不仅能看懂屏幕，还能实际操作电脑——点击、输入、拖拽，几乎像个真人坐在电脑前。

**关键能力：**
- 截图理解 + 坐标定位点击
- 支持多步骤任务拆解
- 失败后能自我纠正

不过说实话，实际用起来还是有不少坑。比如有时候找不到按钮会乱点，或者遇到弹窗就懵圈。但相比之前的方案，已经是质的飞跃。

---

## OpenAI Operator：浏览器里的智能助手

2025 年初，OpenAI 推出了 Operator，专注于浏览器自动化。和 Claude 的通用 Computer Use 不同，Operator 更像是一个专门训练过的"浏览器代理"。

**特点：**
- 基于 CUA（Computer Using Agent）模型
- 内置浏览器环境，安全隔离
- 可以预订机票、填表单、购物结账

OpenAI 特别强调安全性——Operator 在沙盒环境中运行，遇到敏感操作会暂停让用户确认。这种设计虽然慢一点，但至少不会乱花钱 😂

---

## OmniParser：微软的屏幕理解方案

微软研究院的 OmniParser 走了一条不同的路。他们不是训练端到端的 Agent，而是做了一个专门理解 UI 屏幕的模块。

**技术思路：**
- 把屏幕截图解析成结构化的 UI 元素
- 检测可交互区域（按钮、输入框等）
- 生成描述性标签

这种解耦设计的好处是，它可以和任何 LLM 配合，相当于给大模型配了一副"UI 识别眼镜"。

---

## 国内进展：通义千问、智谱跟进了

国内大厂也没闲着：

**阿里通义千问**：推出了自己的 Computer Use 能力，在魔搭社区有演示。能自动操作淘宝下单、查物流，本土化做得不错。

**智谱清言**：GLM-4 支持工具调用 + 视觉理解，虽然主打的不是 GUI Agent，但基础能力已经具备。

**字节跳动**：有传闻在研发类似的 Agent 能力，但还没正式发布。

---

## 开源社区：OSWorld、SeeClick 等

学术界和开源社区也有不少好东西：

- **OSWorld**：可复现的计算机操作环境，用于训练和评测
- **SeeClick**：专门做 UI 元素定位的视觉模型
- **CogAgent**：智源发布的 GUI Agent 模型，开源可玩

这些项目降低了进入门槛，让更多人能参与 GUI Agent 的研发。

---

## 写在最后

GUI Agent 正在从"实验室玩具"走向"实用工具"。虽然目前还谈不上完美，但进步速度惊人。

**值得关注的问题：**
- 安全边界怎么定？Agent 操作出错谁负责？
- 隐私保护——让 AI 看屏幕，敏感信息怎么办？
- 通用性 vs 专用性——做全能型还是垂直场景？

不管怎样，2025 年 GUI Agent 肯定会有更多落地案例。保持关注吧。

---

*本文整理于 2025 年 2 月，信息来源包括官方博客、技术论文和实测体验。*
