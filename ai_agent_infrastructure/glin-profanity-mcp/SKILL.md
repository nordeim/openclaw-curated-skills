---
name: glin-profanity-mcp
description: MCP server providing profanity detection tools for AI assistants. Use when reviewing batches of user content, auditing comments for moderation reports, analyzing text for profanity before publishing, or when AI needs content moderation capabilities during workflows.
---

# Glin Profanity MCP Server

MCP (Model Context Protocol) server that provides profanity detection as tools for AI assistants like Claude Desktop, Cursor, and Windsurf.

**Best for:** AI-assisted content review workflows, batch moderation, audit reports, and content validation before publishing.

## Installation

### Claude Desktop

Add to `~/Library/Application Support/Claude/claude_desktop_config.json`:

```json
{
  "mcpServers": {
    "glin-profanity": {
      "command": "npx",
      "args": ["-y", "glin-profanity-mcp"]
    }
  }
}
```

### Cursor

Add to `.cursor/mcp.json`:

```json
{
  "mcpServers": {
    "glin-profanity": {
      "command": "npx",
      "args": ["-y", "glin-profanity-mcp"]
    }
  }
}
```

## Available Tools

### Core Detection

| Tool | Description |
|------|-------------|
| `check_profanity` | Check text for profanity with detailed results |
| `censor_text` | Censor profanity with configurable replacement |
| `batch_check` | Check multiple texts at once (up to 100) |
| `validate_content` | Get safety score (0-100) with action recommendation |

### Analysis

| Tool | Description |
|------|-------------|
| `analyze_context` | Context-aware analysis (medical, gaming, etc.) |
| `detect_obfuscation` | Detect leetspeak and Unicode tricks |
| `explain_match` | Explain why text was flagged |
| `compare_strictness` | Compare detection across strictness levels |

### Utilities

| Tool | Description |
|------|-------------|
| `suggest_alternatives` | Suggest clean replacements |
| `analyze_corpus` | Analyze up to 500 texts for stats |
| `create_regex_pattern` | Generate regex for custom detection |
| `get_supported_languages` | List all 24 supported languages |

### User Tracking

| Tool | Description |
|------|-------------|
| `track_user_message` | Track messages for repeat offenders |
| `get_user_profile` | Get user's moderation history |
| `get_high_risk_users` | List users with high violation rates |

## Example Prompts

### Content Review
```
"Check these 50 user comments and tell me which ones need moderation"
"Validate this blog post before publishing - use high strictness"
"Analyze this medical article with medical domain context"
```

### Batch Operations
```
"Batch check all messages in this array and return only flagged ones"
"Generate a moderation audit report for these comments"
```

### Understanding Flags
```
"Explain why 'f4ck' was detected as profanity"
"Compare strictness levels for this gaming chat message"
```

### Content Cleanup
```
"Suggest professional alternatives for this flagged text"
"Censor the profanity but preserve first letters"
```

## When to Use

**Use MCP server when:**
- AI assists with content review workflows
- Batch checking user submissions
- Generating moderation reports
- Content validation before publishing
- Human-in-the-loop moderation

**Use core library instead when:**
- Automated real-time filtering (hooks/middleware)
- Every message needs checking without AI involvement
- Performance-critical applications (< 1ms response)

## Resources

- npm: https://www.npmjs.com/package/glin-profanity-mcp
- GitHub: https://github.com/GLINCKER/glin-profanity/tree/release/packages/mcp
- Core library: https://www.npmjs.com/package/glin-profanity
