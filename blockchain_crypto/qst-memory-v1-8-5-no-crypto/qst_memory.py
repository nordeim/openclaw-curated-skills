#!/usr/bin/env python3
"""
QST Memory System v1.5
æ¨¹ç‹€åˆ†é¡ + æ··åˆæœç´¢ + è‡ªå‹•åˆ†é¡ + è¨˜æ†¶è¡°æ¸›

============================================
ğŸŒ³ æ¨¹ç‹€åˆ†é¡ï¼š34 åˆ†é¡ (6 æ ¹ â†’ 18 L2 â†’ 10 L3)
ğŸ” ä¸‰ç¨®æœç´¢ï¼šTree / Selection Rule / Semantic
ğŸ¤– è‡ªå‹•åˆ†é¡ï¼šæ™ºèƒ½æ¨æ–·åˆ†é¡
ğŸ§¹ è¨˜æ†¶è¡°æ¸›ï¼šè‡ªå‹•æ¸…ç†éæœŸè¨˜æ†¶
============================================

Usage:
    python qst_memory.py search "æš—ç‰©è³ª"
    python qst_memory.py search "ARMèŠ¯ç‰‡" --hybrid
    python qst_memory.py save "é‡è¦æ±ºå®šï¼šæ¡ç”¨ FSCA v7"
    python qst_memory.py classify "QSTæš—ç‰©è³ªè¨ˆç®—"
    python qst_memory.py cleanup --dry-run
    python qst_memory.py stats
"""

import argparse
import sys
from pathlib import Path

# æ·»åŠ è…³æœ¬ç›®éŒ„åˆ°è·¯å¾‘
SCRIPT_DIR = Path(__file__).parent / "scripts"
sys.path.insert(0, str(SCRIPT_DIR))

from tree_search import tree_search as ts
from bfs_search import bfs_search as bs
from semantic_search import semantic_search as ss
from semantic_search_v15 import semantic_search_enhanced
from hybrid_search import hybrid_search
from auto_classify import auto_classify, suggest_category
from save_memory import save_memory
from stats_panel import stats_panel
from cleanup import cleanup_memories, print_status


def cmd_search(args):
    """æœç´¢å‘½ä»¤"""
    if args.method == "tree":
        result = ts(args.query, args.path)
    elif args.method == "bfs":
        result = bs(args.query, args.root)
    elif args.method == "semantic":
        result = ss(args.query, args.expand)
    elif args.method == "enhanced":
        context = args.context.split(",") if args.context else None
        result = semantic_search_enhanced(
            args.query,
            context=context,
            expand=args.expand,
            min_relevance=args.min_relevance
        )
    elif args.method == "hybrid":
        methods = [m.strip() for m in args.methods.split(",")]
        context = args.context.split(",") if args.context else None
        result = hybrid_search(args.query, methods=methods, context=context)
    else:
        # é»˜èªä½¿ç”¨æ··åˆæœç´¢
        result = hybrid_search(args.query)
    
    # é¡¯ç¤ºè·¯å¾‘
    path = result.get('path', result.get('primary', 'Root'))
    if isinstance(path, list):
        path_display = ' â†’ '.join(path)
    elif isinstance(path, str):
        path_display = path
    else:
        path_display = 'Root'
    
    print(f"\nğŸ“ Path: {path_display}")
    print(f"ğŸ”— Related: {', '.join(result.get('related', [])[:5])}")
    print(f"ğŸ”‘ Keywords: {', '.join(result.get('keywords', [])[:5])}")
    print(f"ğŸ“Š Found: {result.get('count', len(result.get('results', [])))} memories\n")
    
    for i, r in enumerate(result.get('results', result.get('memories', []))[:5], 1):
        content = r if isinstance(r, str) else r.get('content', str(r))
        print(f"--- Memory {i} ---")
        print(content[:200] + "..." if len(content) > 200 else content)
        print()


def cmd_save(args):
    """ä¿å­˜è¨˜æ†¶å‘½ä»¤"""
    # ç²å–å…§å®¹
    if args.file:
        with open(args.file, 'r', encoding='utf-8') as f:
            content = f.read()
    else:
        content = args.content
    
    # ä¿å­˜è¨˜æ†¶
    result = save_memory(
        content,
        category=args.category,
        weight=args.weight,
        auto_classify=not args.no_auto_classify,
        auto_weight=not args.no_auto_weight
    )
    
    if result["success"]:
        print(f"\nâœ… è¨˜æ†¶å·²ä¿å­˜ï¼")
        print(f"   åˆ†é¡: {result['category']}")
        print(f"   æ¬Šé‡: [{result['weight']}]")
        print(f"   ç´¢å¼•: #{result['index']}")
        if result.get('auto_classified'):
            print(f"   è‡ªå‹•åˆ†é¡: âœ… ({result['reasoning']})")
    else:
        print(f"\nâŒ ä¿å­˜å¤±æ•—ï¼")


def cmd_classify(args):
    """è‡ªå‹•åˆ†é¡å‘½ä»¤"""
    # ç²å–å…§å®¹
    if args.file:
        with open(args.file, 'r', encoding='utf-8') as f:
            content = f.read()
    else:
        content = args.content
    
    result = auto_classify(content)
    
    print(f"\nğŸ“Š åˆ†é¡çµæœ")
    print(f"{'='*50}")
    print(f"ğŸ·ï¸ å»ºè­°åˆ†é¡: {result['suggested_category']}")
    print(f"ğŸ“ˆ ç½®ä¿¡åº¦: {result['confidence']}")
    print(f"ğŸ¯ åˆ†æ•¸: {result['primary_score']}")
    print(f"ğŸ’¡ æ¨ç†: {result['reasoning']}")
    
    print(f"\nğŸ”‘ é—œéµè©: {', '.join(result['keywords'][:10])}")
    
    if result.get('alternatives'):
        print(f"\nğŸ”„ å‚™é¸:")
        for alt in result['alternatives']:
            print(f"  â€¢ {alt['category']} ({alt['score']}) - {alt['confidence']}")


def cmd_suggest(args):
    """å»ºè­°åˆ†é¡å‘½ä»¤"""
    keywords = [k.strip() for k in args.keywords.split(",")]
    
    config_file = Path(__file__).parent / "config.yaml"
    import yaml
    config = yaml.safe_load(config_file.read_text()) if config_file.exists() else {}
    
    suggestion = suggest_category(" ".join(keywords), config)
    
    print(f"\nğŸ’¡ å»ºè­°: {suggestion['reasoning']}")
    
    if suggestion.get('suggested_parent'):
        print(f"ğŸ“ çˆ¶åˆ†é¡: {suggestion['suggested_parent']}")
    
    if suggestion.get('suggested_name'):
        print(f"ğŸ·ï¸ å»ºè­°åç¨±: {suggestion['suggested_name']}")


def cmd_cleanup(args):
    """æ¸…ç†å‘½ä»¤"""
    if args.status:
        print_status()
    elif args.dry_run:
        report = cleanup_memories(dry_run=True)
        print(f"\nğŸ§¹ é è¦½æ¸…ç†")
        print(f"{'='*50}")
        print(f"ç¸½è¨˜æ†¶: {report['summary']['total']}")
        print(f"ä¿ç•™: {report['summary']['kept']}")
        print(f"æ­¸æª”: {report['summary']['archived']}")
        print(f"åˆªé™¤: {report['summary']['deleted']}")
    elif args.run:
        report = cleanup_memories(dry_run=False)
        print(f"\nğŸ§¹ æ¸…ç†å®Œæˆ")
        print(f"{'='*50}")
        print(f"æ­¸æª”: {report['summary']['archived']}")
        print(f"åˆªé™¤: {report['summary']['deleted']}")
    else:
        print("\nç”¨æ³•:")
        print("  python qst_memory.py cleanup --status   # æŸ¥çœ‹ç‹€æ…‹")
        print("  python qst_memory.py cleanup --dry-run  # é è¦½æ¸…ç†")
        print("  python qst_memory.py cleanup --run      # åŸ·è¡Œæ¸…ç†")


def cmd_stats(args):
    """çµ±è¨ˆå‘½ä»¤"""
    output = "json" if args.json else "text"
    result = stats_panel(output)
    
    if args.json:
        import json
        print(json.dumps(result, ensure_ascii=False, indent=2))
    else:
        print(result)


def main():
    parser = argparse.ArgumentParser(
        description="QST Memory System v1.5",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
============================================
ğŸŒ³ Tree-Based Classification (34 categories)
ğŸ” Multi-Mode Search (Tree/BFS/Semantic/Enhanced/Hybrid)
ğŸ¤– Auto-Classification with AI inference
ğŸ§¹ Memory Decay & Cleanup System
============================================

Examples:
  search:
    python qst_memory.py search "æš—ç‰©è³ª"
    python qst_memory.py search "ARMèŠ¯ç‰‡" --method enhanced
    python qst_memory.py search "ARMèŠ¯ç‰‡" --method hybrid --context "æŠ€è¡“è¨è«–"
  
  save memory:
    python qst_memory.py save "æ¡ç”¨ FSCA v7 ä½œç‚ºæš—ç‰©è³ªç†è«–"
    python qst_memory.py save --file memory.txt --weight I
  
  auto-classify:
    python qst_memory.py classify "QSTæš—ç‰©è³ªä½¿ç”¨FSCAç†è«–"
    python qst_memory.py classify --file content.txt
  
  cleanup:
    python qst_memory.py cleanup --status
    python qst_memory.py cleanup --dry-run
    python qst_memory.py cleanup --run
  
  stats:
    python qst_memory.py stats
    python qst_memory.py stats --json
        """
    )
    
    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")
    
    # search å‘½ä»¤
    search_parser = subparsers.add_parser("search", help="æœç´¢è¨˜æ†¶")
    search_parser.add_argument("query", help="æœç´¢æŸ¥è©¢")
    search_parser.add_argument("--method", "-m", 
                              choices=["tree", "bfs", "semantic", "enhanced", "hybrid"],
                              default="hybrid", help="æœç´¢æ–¹æ³•")
    search_parser.add_argument("--path", help="æ¨¹ç‹€è·¯å¾‘ (tree æ–¹æ³•)")
    search_parser.add_argument("--root", help="æ ¹åˆ†é¡ (bfs æ–¹æ³•)")
    search_parser.add_argument("--expand", action="store_true",
                              help="æ“´å±•ç›¸é—œåˆ†é¡ (semantic/enhanced æ–¹æ³•)")
    search_parser.add_argument("--min-relevance", type=float, default=0.1,
                             help="æœ€å°ç›¸é—œåº¦ (enhanced æ–¹æ³•)")
    search_parser.add_argument("--methods", default="tree,selection,semantic",
                             help="æ··åˆæœç´¢æ–¹æ³• (hybrid æ–¹æ³•)")
    search_parser.add_argument("--context", "-c", help="ä¸Šä¸‹æ–‡ (comma-separated)")
    
    # save å‘½ä»¤
    save_parser = subparsers.add_parser("save", help="ä¿å­˜è¨˜æ†¶")
    save_parser.add_argument("content", nargs="?", help="è¨˜æ†¶å…§å®¹")
    save_parser.add_argument("--file", "-f", help="æ–‡ä»¶è·¯å¾‘")
    save_parser.add_argument("--category", "-c", help="æŒ‡å®šåˆ†é¡")
    save_parser.add_argument("--weight", "-w", choices=["C", "I", "N"], help="æ¬Šé‡")
    save_parser.add_argument("--no-auto-classify", action="store_true", help="ç¦ç”¨è‡ªå‹•åˆ†é¡")
    save_parser.add_argument("--no-auto-weight", action="store_true", help="ç¦ç”¨è‡ªå‹•æ¬Šé‡")
    
    # classify å‘½ä»¤
    classify_parser = subparsers.add_parser("classify", help="è‡ªå‹•åˆ†é¡")
    classify_parser.add_argument("content", nargs="?", help="è¦åˆ†é¡çš„å…§å®¹")
    classify_parser.add_argument("--file", "-f", help="æ–‡ä»¶è·¯å¾‘")
    
    # suggest å‘½ä»¤
    suggest_parser = subparsers.add_parser("suggest", help="å»ºè­°åˆ†é¡")
    suggest_parser.add_argument("--keywords", required=True, help="é—œéµè© (é€—è™Ÿåˆ†éš”)")
    
    # cleanup å‘½ä»¤
    cleanup_parser = subparsers.add_parser("cleanup", help="æ¸…ç†è¨˜æ†¶")
    cleanup_parser.add_argument("--status", action="store_true", help="æŸ¥çœ‹ç‹€æ…‹")
    cleanup_parser.add_argument("--dry-run", action="store_true", help="é è¦½æ¸…ç†")
    cleanup_parser.add_argument("--run", action="store_true", help="åŸ·è¡Œæ¸…ç†")
    
    # stats å‘½ä»¤
    stats_parser = subparsers.add_parser("stats", help="çµ±è¨ˆé¢æ¿")
    stats_parser.add_argument("--json", action="store_true", help="JSON è¼¸å‡º")
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # åˆ†ç™¼å‘½ä»¤
    if args.command == "search":
        cmd_search(args)
    elif args.command == "save":
        cmd_save(args)
    elif args.command == "classify":
        cmd_classify(args)
    elif args.command == "suggest":
        cmd_suggest(args)
    elif args.command == "cleanup":
        cmd_cleanup(args)
    elif args.command == "stats":
        cmd_stats(args)


if __name__ == "__main__":
    main()
