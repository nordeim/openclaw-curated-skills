#!/usr/bin/env python3
"""
Semantic Search v1.4 - èªžç¾©é—œè¯æœç´¢
æ ¹æ“šé—œè¯åº¦æ“´å±•ï¼Œæœç´¢ç›¸é—œåˆ†é¡ž

ä¾‹å¦‚: "æš—ç‰©è³ª" â†’ FSCA â†’ ä¹Ÿæœ QST_Computation, QST_Audit

Usage:
    python semantic_search.py "æš—ç‰©è³ªè¨ˆç®—"
    python semantic_search.py --expand
"""

import json
import re
import yaml
from pathlib import Path
from typing import Optional, Set

SKILL_DIR = Path(__file__).parent.parent
CONFIG_FILE = SKILL_DIR / "config.yaml"
MEMORY_FILE = SKILL_DIR / "data" / "qst_memories.md"  # ç¨ç«‹å­˜å„²


def load_config() -> dict:
    """è¼‰å…¥é…ç½®"""
    if CONFIG_FILE.exists():
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    return {"tree": {}}


def load_memory() -> list:
    """è¼‰å…¥è¨˜æ†¶"""
    memories = []
    if MEMORY_FILE.exists():
        with open(MEMORY_FILE, 'r', encoding='utf-8') as f:
            content = f.read()
            entries = re.split(r'\n---+\n', content)
            for entry in entries:
                if entry.strip():
                    memories.append(entry.strip())
    return memories


def get_related_categories(primary: str, config: dict) -> Set[str]:
    """
    ç²å–ç›¸é—œåˆ†é¡ž
    
    å¾žé…ç½®ä¸­è®€å– related æ¬„ä½
    """
    related = set()
    tree = config.get("tree", {})
    
    # éžæ­¸æœç´¢ç¯€é»ž
    def find_node(data: dict, target: str):
        for name, node in data.items():
            if name == target or target in name.lower():
                node_related = node.get("related", [])
                related.update(node_related)
            
            children = node.get("children", {})
            if children:
                find_node(children, target)
    
    find_node(tree, primary)
    
    # æ·»åŠ åå‘é—œè¯
    related.add(primary)
    
    return related


def expand_by_keywords(query: str, config: dict) -> Set[str]:
    """
    æ ¹æ“šé—œéµè©žæ“´å±•åˆ†é¡ž
    
    ä¾‹å¦‚: "è¨ˆç®—" + "æš—ç‰©è³ª" â†’ QST_Computation + QST_Physics
    """
    categories = set()
    tree = config.get("tree", {})
    query_lower = query.lower()
    
    # éžæ­¸æŽƒææ‰€æœ‰ç¯€é»ž
    def scan_nodes(data: dict):
        for name, node in data.items():
            keywords = node.get("keywords", [])
            for kw in keywords:
                if kw.lower() in query_lower:
                    categories.add(name)
                    # æ·»åŠ ç›¸é—œåˆ†é¡ž
                    categories.update(node.get("related", []))
                    break
            
            children = node.get("children", {})
            if children:
                scan_nodes(children)
    
    scan_nodes(tree)
    
    return categories


def semantic_search(query: str, expand: bool = True) -> dict:
    """
    èªžç¾©æœç´¢ä¸»å‡½æ•¸
    
    Args:
        query: æœç´¢æŸ¥è©¢
        expand: æ˜¯å¦æ“´å±•ç›¸é—œåˆ†é¡ž
    
    Returns:
        {
            "primary": "FSCA",
            "related": ["QST_Computation", "QST_Audit"],
            "keywords": [...],
            "results": [...],
            "count": 5
        }
    """
    config = load_config()
    memories = load_memory()
    tree = config.get("tree", {})
    
    # è­˜åˆ¥ä¸»è¦åˆ†é¡ž
    categories = expand_by_keywords(query, config)
    
    if not categories:
        categories = {"General"}
    
    primary = list(categories)[0] if categories else None
    
    # æ“´å±•ç›¸é—œåˆ†é¡ž
    if expand and primary:
        related = get_related_categories(primary, config)
        categories.update(related)
    else:
        related = set()
    
    # æ”¶é›†æ‰€æœ‰é—œéµè©ž
    keywords = collect_keywords(categories, config)
    
    # æœç´¢è¨˜æ†¶
    results = search_by_keywords(memories, keywords, categories)
    
    return {
        "primary": primary,
        "related": list(related - {primary}) if primary else [],
        "keywords": list(keywords)[:10],
        "results": results,
        "count": len(results)
    }


def collect_keywords(categories: Set[str], config: dict) -> Set[str]:
    """æ”¶é›†æ‰€æœ‰ç›¸é—œé—œéµè©ž"""
    keywords = set()
    tree = config.get("tree", {})
    
    def find_keywords(data: dict):
        for name, node in data.items():
            if name in categories:
                keywords.update(node.get("keywords", []))
            
            children = node.get("children", {})
            if children:
                find_keywords(children)
    
    find_keywords(tree)
    
    return keywords


def search_by_keywords(memories: list, keywords: Set[str], categories: Set[str]) -> list:
    """æ ¹æ“šé—œéµè©žæœç´¢è¨˜æ†¶"""
    results = []
    
    for memory in memories:
        # æª¢æŸ¥æ¨™ç±¤
        has_tag = any(f"[{cat}]" in memory for cat in categories)
        
        # æª¢æŸ¥é—œéµè©ž
        has_keyword = any(kw.lower() in memory.lower() for kw in keywords)
        
        if has_tag or has_keyword:
            results.append(memory)
    
    return results[:10]


# èªžç¾©ç­‰åƒ¹æ˜ å°„
SEMANTIC_EQUIVALENCES = {
    "é‚£å€‹å‹•æ¼«": ["Dragon Ball", "é¾ç "],
    "ä»–": ["ç”¨æˆ¶", "ç§¦çŽ‹", "é™›ä¸‹"],
    "å¥¹": ["ç”¨æˆ¶"],
    "ä½ ": ["ä¸žç›¸", "æŽæ–¯"],
    "ä¹‹å‰èªªéŽ": ["MEMORY.md", "è¨˜æ†¶"],
    "å–œæ­¡ä»€éº¼": ["åå¥½", "preference"],
    "QSTæš—ç‰©è³ª": ["FSCA", "æš—ç‰©è³ª", "dark matter", "torsion"],
    "é‚Šé˜²": ["Border", "Security", "VPN", "firewall"],
}


def expand_semantic_query(query: str) -> str:
    """
    æ“´å±•èªžç¾©ç­‰åƒ¹è©ž
    
    ä¾‹å¦‚: "é‚£å€‹å‹•æ¼«" â†’ "é‚£å€‹å‹•æ¼« Dragon Ball é¾ç "
    """
    expanded = query
    
    for phrase, equivalents in SEMANTIC_EQUIVALENCES.items():
        if phrase in query:
            expanded += " " + " ".join(equivalents)
    
    return expanded


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Semantic Search for QST Memory")
    parser.add_argument("query", help="Search query")
    parser.add_argument("--expand", action="store_true", help="Expand related categories")
    parser.add_argument("--verbose", "-v", action="store_true", help="Verbose output")
    
    args = parser.parse_args()
    
    # æ“´å±•èªžç¾©
    expanded_query = expand_semantic_query(args.query)
    
    result = semantic_search(expanded_query, args.expand)
    
    print(f"\nðŸŽ¯ Primary: {result['primary']}")
    print(f"ðŸ”— Related: {', '.join(result['related'][:5])}")
    print(f"ðŸ”‘ Keywords: {', '.join(result['keywords'][:5])}")
    print(f"ðŸ“Š Found: {result['count']} memories\n")
    
    if args.verbose:
        for i, r in enumerate(result['results'][:5], 1):
            print(f"--- Memory {i} ---")
            print(r[:200] + "..." if len(r) > 200 else r)
            print()
