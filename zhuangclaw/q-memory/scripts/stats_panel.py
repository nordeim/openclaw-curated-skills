#!/usr/bin/env python3
"""
Stats Panel v1.5 - è¨˜æ†¶çµ±è¨ˆé¢æ¿
å¯è¦–åŒ–è¨˜æ†¶ç‹€æ…‹

Usage:
    python stats_panel.py
    python stats_panel.py --json
"""

import json
import re
import yaml
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List

SKILL_DIR = Path(__file__).parent.parent
CONFIG_FILE = SKILL_DIR / "config.yaml"
MEMORY_DIR = SKILL_DIR.parent / "memory"
MEMORY_FILE = SKILL_DIR / "data" / "qst_memories.md"  # ç¨ç«‹å­˜å„²


def load_config() -> dict:
    """è¼‰å…¥é…ç½®"""
    if CONFIG_FILE.exists():
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    return {}


def count_categories(config: dict) -> dict:
    """çµ±è¨ˆåˆ†é¡æ•¸é‡"""
    counts = {
        "roots": 0,
        "level1": 0,
        "level2": 0,
        "level3": 0,
        "total": 0
    }
    
    tree = config.get("tree", {})
    
    def scan(data: dict, depth: int = 0):
        nonlocal counts
        for name, node in data.items():
            counts["total"] += 1
            if depth == 0:
                counts["roots"] += 1
            elif depth == 1:
                counts["level1"] += 1
            elif depth == 2:
                counts["level2"] += 1
            else:
                counts["level3"] += 1
            
            children = node.get("children", {})
            if children:
                scan(children, depth + 1)
    
    scan(tree)
    
    return counts


def count_memories() -> dict:
    """çµ±è¨ˆè¨˜æ†¶æ•¸é‡"""
    counts = {
        "critical": 0,
        "important": 0,
        "normal": 0,
        "total": 0
    }
    
    # å¾ç¨ç«‹å­˜å„²è®€å–
    if MEMORY_FILE.exists():
        with open(MEMORY_FILE, 'r', encoding='utf-8') as f:
            content = f.read()
            
            counts["critical"] += content.count("[C]")
            counts["important"] += content.count("[I]")
            counts["normal"] += content.count("[N]")
    
    counts["total"] = counts["critical"] + counts["important"] + counts["normal"]
    
    return counts


def estimate_token_usage() -> dict:
    """ä¼°ç®— Token ä½¿ç”¨"""
    counts = count_memories()
    
    # ä¼°ç®—æ¯æ¢è¨˜æ†¶çš„å¹³å‡ token æ•¸
    avg_tokens = {
        "critical": 100,  # Critical è¨˜æ†¶è¼ƒè©³ç´°
        "important": 50,
        "normal": 30
    }
    
    return {
        "critical": counts["critical"] * avg_tokens["critical"],
        "important": counts["important"] * avg_tokens["important"],
        "normal": counts["normal"] * avg_tokens["normal"],
        "total": counts["critical"] * avg_tokens["critical"] +
                 counts["important"] * avg_tokens["important"] +
                 counts["normal"] * avg_tokens["normal"]
    }


def get_recent_activity(days: int = 7) -> dict:
    """ç²å–æœ€è¿‘æ´»å‹•"""
    activity = {
        "files": [],
        "memories": 0
    }
    
    cutoff = datetime.now() - timedelta(days=days)
    
    memory_files = list(MEMORY_DIR.glob("*.md"))
    
    for mf in sorted(memory_files, reverse=True):
        mtime = datetime.fromtimestamp(mf.stat().st_mtime)
        
        if mtime >= cutoff:
            activity["files"].append({
                "name": mf.name,
                "modified": mtime.strftime("%Y-%m-%d %H:%M")
            })
            
            with open(mf, 'r', encoding='utf-8') as f:
                content = f.read()
                activity["memories"] += content.count("## ")
    
    return activity


def get_category_distribution(config: dict) -> dict:
    """ç²å–åˆ†é¡åˆ†ä½ˆ"""
    tree = config.get("tree", {})
    distribution = {}
    
    for root_name, root_data in tree.items():
        count = count_nodes(root_data)
        distribution[root_name] = count
    
    return distribution


def count_nodes(data: dict) -> int:
    """çµ±è¨ˆç¯€é»æ•¸é‡ï¼ˆåŒ…æ‹¬å­ç¯€é»ï¼‰"""
    count = 1  # ç•¶å‰ç¯€é»
    
    for child in data.get("children", {}).values():
        count += count_nodes(child)
    
    return count


def stats_panel(output: str = "text") -> dict:
    """
    çµ±è¨ˆé¢æ¿ä¸»å‡½æ•¸
    
    Returns:
        çµ±è¨ˆçµæœå­—å…¸
    """
    config = load_config()
    
    stats = {
        "timestamp": datetime.now().isoformat(),
        "version": "1.4",
        "categories": count_categories(config),
        "memories": count_memories(),
        "tokens": estimate_token_usage(),
        "recent_activity": get_recent_activity(),
        "distribution": get_category_distribution(config)
    }
    
    if output == "json":
        return stats
    
    # æ ¼å¼åŒ–è¼¸å‡º
    output_lines = [
        "=" * 50,
        "ğŸ“Š QST Memory v1.5 çµ±è¨ˆé¢æ¿",
        "=" * 50,
        "",
        f"â° çµ±è¨ˆæ™‚é–“: {stats['timestamp']}",
        "",
        "â”€" * 50,
        "ğŸŒ³ åˆ†é¡çµæ§‹",
        "â”€" * 50,
        f"  æ ¹åˆ†é¡ (L1): {stats['categories']['roots']}",
        f"  äºŒç´šåˆ†é¡ (L2): {stats['categories']['level1']}",
        f"  ä¸‰ç´šåˆ†é¡ (L3): {stats['categories']['level2']}",
        f"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€",
        f"  ç¸½è¨ˆ: {stats['categories']['total']} å€‹åˆ†é¡",
        "",
        "â”€" * 50,
        "ğŸ’¾ è¨˜æ†¶çµ±è¨ˆ",
        "â”€" * 50,
        f"  [C] Critical: {stats['memories']['critical']}",
        f"  [I] Important: {stats['memories']['important']}",
        f"  [N] Normal: {stats['memories']['normal']}",
        f"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€",
        f"  ç¸½è¨ˆ: {stats['memories']['total']} æ¢",
        "",
        "â”€" * 50,
        "ğŸ”¢ Token ä¼°ç®—",
        "â”€" * 50,
        f"  Critical: ~{stats['tokens']['critical']:,} tokens",
        f"  Important: ~{stats['tokens']['important']:,} tokens",
        f"  Normal: ~{stats['tokens']['normal']:,} tokens",
        f"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€",
        f"  ç¸½è¨ˆ: ~{stats['tokens']['total']:,} tokens",
        "",
        "â”€" * 50,
        "ğŸ“ åˆ†é¡åˆ†ä½ˆ",
        "â”€" * 50,
    ]
    
    for cat, count in sorted(stats["distribution"].items(), key=lambda x: -x[1]):
        output_lines.append(f"  {cat}: {count}")
    
    output_lines.extend([
        "",
        "â”€" * 50,
        "ğŸ• æœ€è¿‘æ´»å‹• (7å¤©å…§)",
        "â”€" * 50,
    ])
    
    for f in stats["recent_activity"]["files"][:5]:
        output_lines.append(f"  ğŸ“„ {f['name']} ({f['modified']})")
    
    output_lines.extend([
        "",
        f"  æ–°å¢è¨˜æ†¶: {stats['recent_activity']['memories']} æ¢",
        "",
        "=" * 50,
    ])
    
    return "\n".join(output_lines)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="QST Memory Stats Panel")
    parser.add_argument("--json", action="store_true", help="Output as JSON")
    
    args = parser.parse_args()
    
    result = stats_panel(output="json" if args.json else "text")
    
    if args.json:
        print(json.dumps(result, ensure_ascii=False, indent=2))
    else:
        print(result)
