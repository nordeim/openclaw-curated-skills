"""
QST Short-term Memory - Conversation Buffer

çŸ­è¨˜æ†¶å¯¦ç¾ï¼šå°è©±ä¸Šä¸‹æ–‡ç·©å­˜ï¼Œå¿«é€Ÿå­˜å–ã€‚

è¨­è¨ˆåŸå‰‡ï¼š
- Working Memory: 30 åˆ†é˜å£½å‘½
- HighæµåŠ¨æ€§: Ïƒ â‰ˆ 0.7
- å¿«é€Ÿè¡°æ¸›: Ï„ = Ï„_0 Â· exp(-t/Ï„_decay)
"""

import numpy as np
from typing import List, Tuple, Optional, Deque
from collections import deque
from datetime import datetime, timedelta
import json
import hashlib

from memory_core import (
    QSTMemoryCore, 
    MemorySpinor, 
    E8Projector,
    PHI,
    SIGMA_CRYSTAL
)


# ===== å¸¸æ•¸ =====
WORKING_LIFETIME = timedelta(minutes=30)      # Working è¨˜æ†¶å£½å‘½
SHORT_LIFETIME = timedelta(hours=24)        # Short è¨˜æ†¶å£½å‘½
DECAY_TAU = 300                              # è¡°æ¸›æ™‚é–“å¸¸æ•¸ (ç§’)
TAU_0 = 600                                 # åŸºç¤ Ï„_0
BUFFER_MAX_SIZE = 20                         # å°è©±ç·©å†²æœ€å¤§é•·åº¦


# ===== å°è©±è¼ªæ¬¡ =====
class ConversationTurn:
    """å°è©±è¼ªæ¬¡"""
    
    def __init__(self, 
                 speaker: str,
                 content: str,
                 turn_type: str = "user"):  # "user" | "assistant" | "system"
        """
        åˆå§‹åŒ–å°è©±è¼ªæ¬¡
        
        Args:
            speaker: èªªè©±è€… ID
            content: å…§å®¹
            turn_type: è¼ªæ¬¡é¡å‹
        """
        self.speaker = speaker
        self.content = content
        self.turn_type = turn_type
        self.timestamp = datetime.now()
        self.turn_id = self._generate_id()
        
        # Coherence ç”±å…§å®¹æ±ºå®š
        self.coherence = self._estimate_coherence()
        
    def _generate_id(self) -> str:
        data = f"{self.speaker}_{self.content}_{self.timestamp}"
        return hashlib.md5(data.encode()).hexdigest()[:12]
    
    def _estimate_coherence(self) -> float:
        """
        ä¼°è¨ˆ coherence
        
        åŸå‰‡ï¼š
        - çŸ­å›å¤: Ïƒ â†“ (ä½é‡è¦æ€§)
        - é•·å›å¤: Ïƒ â†‘ (é«˜é‡è¦æ€§)
        - ç³»çµ±æ¶ˆæ¯: Ïƒ â†‘â†‘ (æœ€é«˜)
        """
        base = 0.7
        
        if self.turn_type == "system":
            return min(1.5, base + 0.3)
        elif self.turn_type == "user":
            # é•·åº¦ç›¸é—œ
            length_factor = min(1.0, len(self.content) / 500)
            return min(1.2, base + 0.2 * length_factor)
        else:  # assistant
            # AI å›å¤é€šå¸¸è¼ƒé•·ï¼Œè¼ƒé‡è¦
            length_factor = min(1.0, len(self.content) / 1000)
            return min(1.3, base + 0.15 * length_factor)
    
    def to_dict(self) -> dict:
        return {
            "turn_id": self.turn_id,
            "speaker": self.speaker,
            "content": self.content,
            "turn_type": self.turn_type,
            "timestamp": self.timestamp.isoformat(),
            "coherence": self.coherence
        }
    
    @classmethod
    def from_dict(cls, data: dict) -> 'ConversationTurn':
        turn = cls(
            speaker=data["speaker"],
            content=data["content"],
            turn_type=data["turn_type"]
        )
        turn.turn_id = data["turn_id"]
        turn.timestamp = datetime.fromisoformat(data["timestamp"])
        turn.coherence = data["coherence"]
        return turn


# ===== å°è©±ç·©å†² =====
class ConversationBuffer:
    """
    å°è©±ç·©å†²å®¹å™¨
    
    ç‰¹é»ï¼š
    - FIFO çµæ§‹
    - åŸºæ–¼ coherence çš„è¡°æ¸›
    - è‡ªå‹•æ¸…ç†éæœŸè¨˜æ†¶
    """
    
    def __init__(self, 
                 max_size: int = BUFFER_MAX_SIZE,
                 e8_projector: E8Projector = None):
        """
        åˆå§‹åŒ–å°è©±ç·©å†²
        
        Args:
            max_size: æœ€å¤§ç·©å†²é•·åº¦
            e8_projector: E8 æŠ•å½±å™¨
        """
        self.max_size = max_size
        self.e8_projector = e8_projector or E8Projector()
        self.turns: Deque[ConversationTurn] = deque()
        self.last_cleanup = datetime.now()
        
        # çµ±è¨ˆ
        self.stats = {
            "total_turns": 0,
            "avg_coherence": 0.7,
            "current_context_coherence": 0.7
        }
    
    def add_turn(self, 
                  speaker: str, 
                  content: str, 
                  turn_type: str = "user") -> ConversationTurn:
        """
        æ·»åŠ å°è©±è¼ªæ¬¡
        
        Returns:
            æ–°å‰µå»ºçš„ ConversationTurn
        """
        turn = ConversationTurn(speaker, content, turn_type)
        self.turns.append(turn)
        
        # ç¶­è­·å¤§å°é™åˆ¶
        if len(self.turns) > self.max_size:
            self.turns.popleft()
            
        self.stats["total_turns"] += 1
        self._update_stats()
        
        return turn
    
    def get_recent(self, n: int = 5) -> List[ConversationTurn]:
        """
        ç²å–æœ€è¿‘ n è¼ªå°è©±
        
        Returns:
            ConversationTurn åˆ—è¡¨
        """
        return list(self.turns)[-n:]
    
    def get_context(self, max_turns: int = 10) -> str:
        """
        ç²å–å°è©±ä¸Šä¸‹æ–‡æ–‡æœ¬
        
        Args:
            max_turns: æœ€å¤§è¼ªæ¬¡æ•¸
            
        Returns:
            æ ¼å¼åŒ–ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        recent = self.get_recent(max_turns)
        
        context_parts = []
        for turn in recent:
            prefix = "ğŸ‘¤" if turn.turn_type == "user" else "ğŸ¤–" if turn.turn_type == "assistant" else "âš™ï¸"
            context_parts.append(f"{prefix} {turn.speaker}: {turn.content}")
        
        return "\n".join(context_parts)
    
    def get_coherence_profile(self) -> dict:
        """
        ç²å– coherence é…ç½®æ–‡ä»¶
        
        Returns:
            coherence çµ±è¨ˆ
        """
        coherences = [t.coherence for t in self.turns]
        
        return {
            "turn_count": len(coherences),
            "avg_coherence": np.mean(coherences) if coherences else 0.7,
            "max_coherence": max(coherences) if coherences else 0.7,
            "min_coherence": min(coherences) if coherences else 0.7,
            "decay_factor": self._calculate_decay()
        }
    
    def _calculate_decay(self) -> float:
        """
        è¨ˆç®—æ™‚é–“è¡°æ¸›å› å­
        
        Returns:
            è¡°æ¸›å› å­ (0-1)
        """
        if len(self.turns) == 0:
            return 1.0
            
        # è¨ˆç®—å¹³å‡å¹´é½¡
        now = datetime.now()
        ages = [(now - t.timestamp).total_seconds() for t in self.turns]
        avg_age = np.mean(ages)
        
        # è¡°æ¸›å…¬å¼
        decay = np.exp(-avg_age / DECAY_TAU)
        return decay
    
    def _update_stats(self):
        """æ›´æ–°çµ±è¨ˆ"""
        coherences = [t.coherence for t in self.turns]
        if coherences:
            self.stats["avg_coherence"] = np.mean(coherences)
            self.stats["current_context_coherence"] = (
                self.stats["avg_coherence"] * self._calculate_decay()
            )
    
    def cleanup_expired(self) -> List[ConversationTurn]:
        """
        æ¸…ç†éæœŸè¨˜æ†¶
        
        Returns:
            è¢«åˆªé™¤çš„è¼ªæ¬¡åˆ—è¡¨
        """
        now = datetime.now()
        expired = []
        
        # æ¸…ç† Working è¨˜æ†¶
        while self.turns and (now - self.turns[0].timestamp) > WORKING_LIFETIME:
            expired.append(self.turns.popleft())
            
        self.last_cleanup = now
        return expired
    
    def to_qst_memories(self, 
                        core: QSTMemoryCore,
                        dsi_level: int = 0) -> List[MemorySpinor]:
        """
        å°‡å°è©±è½‰æ›ç‚º QST è¨˜æ†¶
        
        Args:
            core: QST è¨˜æ†¶æ ¸å¿ƒ
            dsi_level: DSI å±¤æ¬¡
            
        Returns:
            MemorySpinor åˆ—è¡¨
        """
        memories = []
        
        for turn in self.turns:
            # å…§å®¹ä½œç‚ºè¨˜æ†¶
            memory = core.encode(
                content=f"[{turn.turn_type}] {turn.speaker}: {turn.content}",
                base_coherence=turn.coherence * self._calculate_decay(),
                dsi_level=dsi_level
            )
            memories.append(memory)
            
        return memories
    
    def save(self, filepath: str):
        """ä¿å­˜ç·©å†²"""
        with open(filepath, 'w') as f:
            json.dump({
                "turns": [t.to_dict() for t in self.turns],
                "stats": self.stats,
                "last_cleanup": self.last_cleanup.isoformat()
            }, f, indent=2)
    
    def load(self, filepath: str):
        """è¼‰å…¥ç·©å†²"""
        with open(filepath, 'r') as f:
            data = json.load(f)
            
        self.turns = deque([ConversationTurn.from_dict(t) for t in data["turns"]])
        self.stats = data["stats"]
        self.last_cleanup = datetime.fromisoformat(data["last_cleanup"])
    
    def clear(self):
        """æ¸…ç©ºç·©å†²"""
        self.turns.clear()
        self.stats = {
            "total_turns": 0,
            "avg_coherence": 0.7,
            "current_context_coherence": 0.7
        }


# ===== çŸ­è¨˜æ†¶ç®¡ç†å™¨ =====
class ShortTermMemory:
    """
    çŸ­è¨˜æ†¶ç®¡ç†å™¨
    
    ç®¡ç†ï¼š
    - Working Memory (å³æ™‚ç·©å†²)
    - Short Memory (24å°æ™‚)
    """
    
    def __init__(self, e8_dim: int = 16):
        """
        åˆå§‹åŒ–
        
        Args:
            e8_dim: E8 æŠ•å½±ç¶­åº¦
        """
        self.e8_projector = E8Projector(dim=e8_dim)
        self.core = QSTMemoryCore(e8_dim=e8_dim)
        self.buffer = ConversationBuffer(e8_projector=self.e8_projector)
        
    def add_conversation(self, 
                         speaker: str,
                         content: str,
                         turn_type: str = "user") -> ConversationTurn:
        """
        æ·»åŠ å°è©±
        
        Returns:
            æ–°è¼ªæ¬¡
        """
        return self.buffer.add_turn(speaker, content, turn_type)
    
    def get_context(self, max_turns: int = 10) -> str:
        """
        ç²å–å°è©±ä¸Šä¸‹æ–‡
        """
        return self.buffer.get_context(max_turns)
    
    def consolidate_to_short(self) -> int:
        """
        å°‡ Working è¨˜æ†¶æ•´åˆåˆ° Short
        
        Returns:
            æ•´åˆæ•¸é‡
        """
        # è½‰æ›ç‚º QST è¨˜æ†¶
        memories = self.buffer.to_qst_memories(
            self.core,
            dsi_level=1  # Short Memory level
        )
        
        # æ¸…ç†éæœŸ
        expired = self.buffer.cleanup_expired()
        
        return len(memories)
    
    def search(self, query: str, top_k: int = 3) -> List[Tuple[MemorySpinor, float]]:
        """
        æœç´¢ç›¸é—œè¨˜æ†¶
        """
        return self.core.retrieve(query, top_k)
    
    def get_coherence_info(self) -> dict:
        """
        ç²å– coherence ä¿¡æ¯
        """
        return self.buffer.get_coherence_profile()
    
    def decay_all(self) -> int:
        """
        å…¨å±€è¡°æ¸›
        
        Returns:
            åˆªé™¤æ•¸é‡
        """
        to_delete = self.core.decay_check()
        self.core.prune(to_delete)
        
        # ä¹Ÿæ¸…ç†ç·©å†²
        expired = self.buffer.cleanup_expired()
        
        return len(to_delete) + len(expired)


# ===== æ¸¬è©¦ =====
if __name__ == "__main__":
    print("=== QST Short-term Memory Test ===\n")
    
    # åˆå§‹åŒ–
    short_mem = ShortTermMemory()
    
    # æ·»åŠ å°è©±
    print("Adding conversations...")
    short_mem.add_conversation("user", "ä½ å¥½ï¼", "user")
    short_mem.add_conversation("assistant", "ç§¦ç‹é™›ä¸‹è¬æ­²ï¼", "assistant")
    short_mem.add_conversation("user", "æˆ‘æ˜¯çš‡å¸", "user")
    short_mem.add_conversation("assistant", "è‡£ææ–¯åƒè¦‹é™›ä¸‹ï¼", "assistant")
    short_mem.add_conversation("user", "QSTæ˜¯ä»€éº¼ï¼Ÿ", "user")
    
    print(f"Buffer turns: {len(short_mem.buffer.turns)}")
    
    # ç²å–ä¸Šä¸‹æ–‡
    print("\n=== Context ===")
    print(short_mem.get_context(5))
    
    # Coherence æª”æ¡ˆ
    print("\n=== Coherence Profile ===")
    print(short_mem.get_coherence_info())
    
    # æœç´¢
    print("\n=== Search Test ===")
    results = short_mem.search("çš‡å¸")
    for mem, score in results:
        print(f"[{score:.3f}] {mem.content[:50]}...")
    
    print("\n=== Complete ===")
