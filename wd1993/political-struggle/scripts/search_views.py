#!/usr/bin/env python3
"""
æœç´¢ä¸­å›½å†å²æ”¿æ²»æ–—äº‰äº‹ä»¶çš„ä¸»æµä¸éä¸»æµè§‚ç‚¹ã€‚

ç”¨æ³•:
    python search_views.py <äº‹ä»¶åç§°> [--lang zh|en|both] [--max-results 10]

ç¤ºä¾‹:
    python search_views.py "ç„æ­¦é—¨ä¹‹å˜"
    python search_views.py "ç‹è½ç¯¡æ±‰" --lang both
    python search_views.py "å®‰å²ä¹‹ä¹±" --max-results 15

ç¯å¢ƒå˜é‡:
    TAVILY_API_KEY - Tavily API å¯†é’¥ï¼ˆå¿…é¡»ï¼‰

è¾“å‡º:
    ç»“æ„åŒ– JSONï¼ŒåŒ…å«ä¸»æµè§‚ç‚¹ã€éä¸»æµè§‚ç‚¹ï¼ˆæ°‘é—´è®ºå› + æµ·å¤–å­¦è€…ï¼‰çš„æ‘˜è¦ã€‚
"""

import argparse
import json
import os
import sys
from dataclasses import dataclass, field, asdict

try:
    from tavily import TavilyClient
except ImportError:
    print("é”™è¯¯: è¯·å…ˆå®‰è£… tavily-python\n  pip install tavily-python", file=sys.stderr)
    sys.exit(1)


@dataclass
class ViewResult:
    title: str
    url: str
    snippet: str
    source_type: str  # mainstream / folk / overseas


@dataclass
class SearchReport:
    event: str
    mainstream: list[ViewResult] = field(default_factory=list)
    folk: list[ViewResult] = field(default_factory=list)
    overseas: list[ViewResult] = field(default_factory=list)


# ---------------------------------------------------------------------------
# æœç´¢ç­–ç•¥é…ç½®
# ---------------------------------------------------------------------------

MAINSTREAM_QUERIES_ZH = [
    "{event} å†å²è¯„ä»·",
    "{event} å­¦æœ¯ç ”ç©¶ è®ºæ–‡",
    "{event} æ­£å²è®°è½½ åˆ†æ",
]

FOLK_QUERIES_ZH = [
    "{event} çŸ¥ä¹ äº‰è®®",
    "{event} è´´å§ è®¨è®º çœŸç›¸",
    "{event} æ°‘é—´ å¦ä¸€ç§è¯´æ³•",
    "{event} é˜´è°‹è®º é‡å²",
]

OVERSEAS_QUERIES_ZH = [
    "{event} æµ·å¤–å­¦è€… è§‚ç‚¹",
    "{event} ç¿»æ¡ˆ é‡æ–°è¯„ä»·",
    "{event} ä¸åŒè§£è¯» æ–°è§†è§’",
]

MAINSTREAM_QUERIES_EN = [
    "{event_en} Chinese history scholarly analysis",
    "{event_en} academic perspective historical evaluation",
]

OVERSEAS_QUERIES_EN = [
    "{event_en} revisionist interpretation",
    "{event_en} alternative historical view controversy",
    "{event_en} Western sinology perspective",
]

# äº‹ä»¶åç§°ä¸­è‹±å¯¹ç…§ï¼ˆå¸¸è§äº‹ä»¶ï¼‰
EVENT_TRANSLATIONS = {
    "ç„æ­¦é—¨ä¹‹å˜": "Xuanwu Gate Incident",
    "å®‰å²ä¹‹ä¹±": "An Lushan Rebellion",
    "é–éš¾ä¹‹å½¹": "Jingnan Campaign",
    "ç‹è½ç¯¡æ±‰": "Wang Mang usurpation",
    "ä¸ƒå›½ä¹‹ä¹±": "Rebellion of the Seven States",
    "å·«è›Šä¹‹ç¥¸": "Witchcraft Incident Han dynasty",
    "é™ˆæ¡¥å…µå˜": "Chenqiao Mutiny",
    "åœŸæœ¨å ¡ä¹‹å˜": "Tumu Crisis",
    "ç”˜éœ²ä¹‹å˜": "Sweet Dew Incident Tang",
    "å…«ç‹ä¹‹ä¹±": "War of the Eight Princes",
    "é«˜å¹³é™µä¹‹å˜": "Gaoping Tombs Incident",
    "å…šé”¢ä¹‹ç¥¸": "Disasters of Partisan Prohibitions",
    "æ­¦å‘¨é©å‘½": "Wu Zetian Zhou dynasty",
    "ç‰›æå…šäº‰": "Niu-Li Factional Strife",
    "ä¹å­å¤ºå«¡": "Nine Princes struggle for succession Kangxi",
    "æˆŠæˆŒå˜æ³•": "Hundred Days Reform",
    "é–åº·ä¹‹å˜": "Jingkang Incident",
    "æ²™ä¸˜ä¹‹å˜": "Shaqiu Incident Qin dynasty",
    "å¤§ç¤¼è®®": "Great Rites Controversy Ming",
    "ä¸œæ—å…šäº‰": "Donglin Movement Ming dynasty",
    "æ–‡å­—ç‹±": "Literary Inquisition Qing dynasty",
    "é³Œæ‹œä¸“æƒ": "Oboi regency Kangxi",
    "ä¸‰å®¶åˆ†æ™‹": "Partition of Jin",
    "å•†é…å˜æ³•": "Shang Yang reforms",
    "ç‹å®‰çŸ³å˜æ³•": "Wang Anshi reforms",
    "åº†å…ƒå…šç¦": "Qingyuan Partisan Ban",
}

# æ¥æºåŸŸååˆ†ç±»
FOLK_DOMAINS = [
    "zhihu.com", "tieba.baidu.com", "tianya.cn", "douban.com",
    "bilibili.com", "weibo.com", "toutiao.com", "sohu.com",
]

MAINSTREAM_DOMAINS = [
    "cnki.net", "cssn.cn", "guoxue.com", "cass.cn",
    "wikipedia.org", "baike.baidu.com", "britannica.com",
    "jstor.org", "academia.edu",
]


def classify_source(url: str) -> str:
    """æ ¹æ® URL åŸŸååˆ¤æ–­æ¥æºç±»å‹ã€‚"""
    url_lower = url.lower()
    for domain in FOLK_DOMAINS:
        if domain in url_lower:
            return "folk"
    for domain in MAINSTREAM_DOMAINS:
        if domain in url_lower:
            return "mainstream"
    # è‹±æ–‡åŸŸåå¤§æ¦‚ç‡æ˜¯æµ·å¤–æ¥æº
    if any(tld in url_lower for tld in [".edu", ".ac.uk", ".org"]):
        return "overseas"
    return "mainstream"


def search_tavily(client: TavilyClient, query: str, max_results: int = 5) -> list[dict]:
    """æ‰§è¡Œå•æ¬¡ Tavily æœç´¢ã€‚"""
    try:
        response = client.search(
            query=query,
            max_results=max_results,
            search_depth="advanced",
            include_answer=False,
        )
        return response.get("results", [])
    except Exception as e:
        print(f"  æœç´¢å‡ºé”™ [{query[:30]}...]: {e}", file=sys.stderr)
        return []


def get_event_english(event: str) -> str:
    """è·å–äº‹ä»¶çš„è‹±æ–‡åç§°ã€‚"""
    if event in EVENT_TRANSLATIONS:
        return EVENT_TRANSLATIONS[event]
    # æ²¡æœ‰é¢„è®¾ç¿»è¯‘å°±ç”¨æ‹¼éŸ³+å…³é”®è¯
    return f"{event} Chinese history"


def run_search(event: str, lang: str, max_results: int) -> SearchReport:
    """æ‰§è¡Œå¤šç»´åº¦æœç´¢å¹¶æ±‡æ€»ç»“æœã€‚"""
    api_key = os.environ.get("TAVILY_API_KEY")
    if not api_key:
        print("é”™è¯¯: è¯·è®¾ç½®ç¯å¢ƒå˜é‡ TAVILY_API_KEY", file=sys.stderr)
        sys.exit(1)

    client = TavilyClient(api_key=api_key)
    report = SearchReport(event=event)
    seen_urls = set()

    def add_results(raw_results: list[dict], default_type: str):
        for r in raw_results:
            url = r.get("url", "")
            if url in seen_urls:
                continue
            seen_urls.add(url)
            source_type = classify_source(url)
            # å¦‚æœåˆ†ç±»ä¸æœç´¢æ„å›¾ä¸ç¬¦ï¼Œä¼˜å…ˆç”¨æœç´¢æ„å›¾
            if default_type == "folk" and source_type == "mainstream":
                source_type = "folk"
            elif default_type == "overseas" and source_type == "mainstream":
                source_type = "overseas"

            vr = ViewResult(
                title=r.get("title", ""),
                url=url,
                snippet=r.get("content", "")[:500],
                source_type=source_type,
            )
            if vr.source_type == "folk":
                report.folk.append(vr)
            elif vr.source_type == "overseas":
                report.overseas.append(vr)
            else:
                report.mainstream.append(vr)

    per_query = max(2, max_results // 5)

    # --- ä¸­æ–‡æœç´¢ ---
    if lang in ("zh", "both"):
        print(f"ğŸ” æœç´¢ä¸»æµè§‚ç‚¹ï¼ˆä¸­æ–‡ï¼‰...", file=sys.stderr)
        for q in MAINSTREAM_QUERIES_ZH:
            results = search_tavily(client, q.format(event=event), per_query)
            add_results(results, "mainstream")

        print(f"ğŸ” æœç´¢æ°‘é—´è®¨è®ºï¼ˆä¸­æ–‡ï¼‰...", file=sys.stderr)
        for q in FOLK_QUERIES_ZH:
            results = search_tavily(client, q.format(event=event), per_query)
            add_results(results, "folk")

        print(f"ğŸ” æœç´¢éä¸»æµ/ç¿»æ¡ˆè§‚ç‚¹ï¼ˆä¸­æ–‡ï¼‰...", file=sys.stderr)
        for q in OVERSEAS_QUERIES_ZH:
            results = search_tavily(client, q.format(event=event), per_query)
            add_results(results, "overseas")

    # --- è‹±æ–‡æœç´¢ ---
    if lang in ("en", "both"):
        event_en = get_event_english(event)
        print(f"ğŸ” Searching mainstream views (English)...", file=sys.stderr)
        for q in MAINSTREAM_QUERIES_EN:
            results = search_tavily(client, q.format(event_en=event_en), per_query)
            add_results(results, "mainstream")

        print(f"ğŸ” Searching alternative views (English)...", file=sys.stderr)
        for q in OVERSEAS_QUERIES_EN:
            results = search_tavily(client, q.format(event_en=event_en), per_query)
            add_results(results, "overseas")

    return report


def format_markdown(report: SearchReport) -> str:
    """å°†æœç´¢ç»“æœæ ¼å¼åŒ–ä¸º Markdownã€‚"""
    lines = []
    lines.append(f"# ã€Œ{report.event}ã€å¤šå…ƒè§‚ç‚¹æœç´¢æŠ¥å‘Š\n")

    def section(title: str, items: list[ViewResult]):
        lines.append(f"## {title}ï¼ˆå…± {len(items)} æ¡ï¼‰\n")
        if not items:
            lines.append("_æš‚æ— æœç´¢ç»“æœ_\n")
            return
        for i, v in enumerate(items, 1):
            lines.append(f"### {i}. {v.title}\n")
            lines.append(f"- **æ¥æº**: [{v.url}]({v.url})")
            lines.append(f"- **æ‘˜è¦**: {v.snippet}\n")

    section("ğŸ“š ä¸»æµ/å­¦æœ¯è§‚ç‚¹", report.mainstream)
    section("ğŸ’¬ æ°‘é—´è®¨è®ºä¸äº‰è®®", report.folk)
    section("ğŸŒ æµ·å¤–å­¦è€…/éä¸»æµè§£è¯»", report.overseas)

    lines.append("---")
    lines.append(f"_å…±æœç´¢åˆ° {len(report.mainstream) + len(report.folk) + len(report.overseas)} æ¡ä¸é‡å¤ç»“æœ_")

    return "\n".join(lines)


def main():
    parser = argparse.ArgumentParser(
        description="æœç´¢ä¸­å›½å†å²æ”¿æ²»æ–—äº‰äº‹ä»¶çš„ä¸»æµä¸éä¸»æµè§‚ç‚¹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python search_views.py "ç„æ­¦é—¨ä¹‹å˜"
  python search_views.py "ç‹è½ç¯¡æ±‰" --lang both --format markdown
  python search_views.py "å®‰å²ä¹‹ä¹±" --max-results 15 --format json
        """,
    )
    parser.add_argument("event", help="å†å²æ”¿æ²»æ–—äº‰äº‹ä»¶åç§°ï¼ˆä¸­æ–‡ï¼‰")
    parser.add_argument(
        "--lang",
        choices=["zh", "en", "both"],
        default="both",
        help="æœç´¢è¯­è¨€: zh=ä»…ä¸­æ–‡, en=ä»…è‹±æ–‡, both=ä¸­è‹±åŒè¯­ï¼ˆé»˜è®¤ï¼‰",
    )
    parser.add_argument(
        "--max-results",
        type=int,
        default=10,
        help="æ¯ä¸ªç±»åˆ«çš„æœ€å¤§ç»“æœæ•°ï¼ˆé»˜è®¤ 10ï¼‰",
    )
    parser.add_argument(
        "--format",
        choices=["json", "markdown"],
        default="markdown",
        help="è¾“å‡ºæ ¼å¼: json æˆ– markdownï¼ˆé»˜è®¤ï¼‰",
    )

    args = parser.parse_args()

    report = run_search(args.event, args.lang, args.max_results)

    if args.format == "json":
        output = json.dumps(asdict(report), ensure_ascii=False, indent=2)
        print(output)
    else:
        print(format_markdown(report))


if __name__ == "__main__":
    main()
